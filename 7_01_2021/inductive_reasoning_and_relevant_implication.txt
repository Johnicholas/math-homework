# MOTIVATION

By ``deductive reasoning'', I mean reasoning ``forward'', from
observed facts and given rules to conclusions guaranteed by those rules.
Going from observed A and given rule A -> B to conclude B (called modus ponens in latin) 
is supposed to be the paradigmatic example of deductive reasoning.

By ``inductive reasoning'', I mean reasoning ``backward'', from
observed facts and given rules to generate plausible hypotheses that might,
upon further investigation, turn out to be true.
From observed A and given B -> A to conclude perhaps B (because that would explain A).

A paradigmatic example of inductive reasoning in math is probabilistic primality testing using Fermat's Little Theorem.

If we choose random number a, and we compute a^(n-1) and we observe that it is 1 mod n,
we know that if a were prime, Fermat's Little Theorem would ``force'' this to be the case,
so we might plausibly speculate that a is prime.
Of course, there are numbers (Carmichael numbers, Fermat pseudoprimes) that make the inductive
inference deductively false; it's an uncertain inference. But the densities of these families of numbers lead to the inductive reasoning actually being practically valuable.
(Maybe it would be good to talk explicitly about densities or probability distributions,
because lots of inductive reasoning principles will fail if there is some kind of
antagonism or adaptation going on, but often it's like ``wanna use a max entropy distribution as our prior? but why? dunno, might work?'' - we could instead not go there, not do that work,
and say that inductive reasoning might work or might not work.)

What's the relationship between relevant implication and inductive reasoning?
Stepping back a bit, what's relevant implication?

There's a step in mathematical reasoning when you translate from informal sentences to formal,
even algebraic, symbols. (Note: Historically, it was Boole who algebraized logic,
and though it might seem like a  natural, or even trivial, thing to do now, it was difficult at
the time.)

Though going from `X and Y' to the truth-functional connective `^' seems unobjectionable,
some people (some philosophers, logicians, and freshmen) find going from `if X then Y' and the truth-functional connective `->' to be odious or even wrong.

In particular, they might object to what are called `fallacies of relevance', where
the antecedent and the consequent seem to be disconnected from one another, 
talking about completely different things.

Examples of fallacies of relevance include`a falsehood implies anything' (also known as `ex falso quodlibet') and `everything implies a truth'.

Some logicians (Anderson and Belnap) have developed a system, relevant implication (R->),
which is generally not truth-functional, and which doesn't suffer from these `fallacies of relevance'.

Why bring up relevant logic?

The point is, irrelevant truth-functional rules are definitely not inductively valid.
If you test a tautology and find it to be true, you cannot conclude anything,
not even some probabilistic or plausibilistic antecedent.

How does this apply to invariant hunting?

One of the things that mathematicians like to do is to invent invariants that help
classify difficult-to-work-with or complicated things. An invariant is a computable
function from some set of difficult-to-work-with or complicated things,
that yields an easy-to-work-with or simple result, and that has a guarantee:
if A is isomorphic to B then inv A = inv B.

We want ``good'' invariants. A good invariant is one where the (ill-specified, informal, or unmodeled) probabilities or densities involved lead us to think that if two things are observed to
have the same invariant, they have increased likelihood to be isomorphic.
That is, a good invariant is one that is inductively valid.

So if we're looking for invariants, maybe we should use relevant logic?

Theorems and axioms of R-> (I'm not sure if I remember which are which):
I: A -> A = \x.x 
B: (A -> B) -> (C -> A) -> C -> B = \xyz.x(yz)
C: (A -> B -> C) -> B -> A -> C = \xyz.xzy 
W: (A -> A -> B) -> A -> B = \xy.xyy
S: (A -> B -> C) -> (A -> B) -> A -> C = \xyz.(xz)(yz)
The forbidden one (throws away data):
K: A -> B -> A = \xy.x

# APPLICATIONS (ISH)

Suppose we had a variety of algebras V (such as Group or Quandle) that we were investigating,
and we wanted a math tool (an invariant) that would let us calculate, at least in some circumstances, that specific pairs of algebras (such as the Klein 4 group and the cyclic
group of order 4) are definitely nonisomorphic.

The specific pairs of algebras presumably have definitions. Let's imagine they even have presentations, names for at least some of their elements (generators, and elements are arrows from the terminal object), and some laws (relations would be laws that apply ``locally'' to a particular algebra, and there are some variety-wide laws that apply to all algebras of this sort.
(Aside: Relations are categorified as coequalizers?)

In order for the invariant to be an invariant, we need it to give the same answer for isomorphic objects. Dropping all the non-isomorphism arrows from a category yields a category
(isomorphisms are closed under arrow composition) and a functor from this V^iso category is a1
``nice map'', and so might be a good way to get an invariant. 

What are some ways that we could end up with a map from V to Z/2Z?

Bxyz = x (y z) is a combinator in combinatory logic,
with type (B->C)->(A->B)->A->C.
We might be able to produce a map from V to Z/2Z via this B combinator.

(That is, suppose our future selves built a map via some procedure; it's entirely possible that the last step  might well be plugging some other maps together somehow.
B is one possible way to plug some maps together; the procedure that we built might end with B. 
'm not trying to say anything particularly insightful or nontrivial here.)

If we did (produce a map via B), then the A in the type of B would be V and the C in the type would be Z/2Z.
(B->Z/2Z)->(V->B)->V->C
Then we would need:
1. to know what type B is
2. some map from B to Z/2Z
3. some map from V to B
The ideas that there should be some map from B to Z/2Z and some map from V to B might
help us triangulate what B might be:
1. What kind of thing plausibly has maps from variety V and to Z/2Z?

One of the ways this might happen is if B were Nat,
then counting something about V might yield a reasonable map from V to Nat.
Then the map from Nat to Z/2Z might be modding by 2.
What we're saying here is that we might get an Z/2Z invariant if we had a (probably better?) invariant, and then we computed it mod 2 - true but not insightful or nontrivial.

Cxyz = x z y is another combinator in combinatory logic,
with type (A->B->C)->B->A->C.
Again, we might be able to produce a map from V to Z/2Z via this C combinator.
It would have type (V->B->Z/2Z)->B->V->Z/2Z
If we did, we would need:
1. to know what type B is
2. some map from V to maps from B to Z/2Z
3. an element of B
Again, the ideas that there should be some map from B to Z/2Z and some map from V to maps B->Z/2Z
might help us triangulate what B might be:
1. Can we imagine what type B might be, that there would be a reasonably natural map from V to maps B->Z/2Z?
2. Do we have any particular, salient or natural elements of that B?

A map to Z/2Z might be viewed as a subset.
If B were the plane R^2, then a map from V to R^2 might be some canonical way of depicting V.
A particular element of the plane might be the origin, or the point (1, 0).
Then we're saying that we might get a Z/2Z invariant by asking whether
"the depiction" of one of these V things contains the special point.

Again, not that insightful, not that interesting.

Sxyz = (x z) (y z) is another combinator in combinatory logic, with type (A->B->C)->(A->B)->A->C.
If we produced this invariant via S, then the A in the type would be V and the C in the type would be Z/2Z: (V->B->Z/2Z)->(V->B)->V->Z/2Z

Then we would need:
1. to know what type B is
2. some map from V to maps from B to Z/2Z
3. some map from V to B

Here we are getting maybe a little bit clever, because we're doing something like diagonalizing.

The Mandelbrot set is maybe an example of this kind of thing.
There's a thing, the Julia set of a dynamical system, which is a subset of the complex plane.
The dynamical system also has a parameter, which can be viewed as a point in the complex plane.
The Mandelbrot set comes from taking all the dynamical systems,
and ``cooking them two ways'', to their Julia sets, and to their points,
and asking whether the point is within the corresponding Julia set.

Similarly, the Gray-Scott reaction diffusion system is parameterized by a pair of numbers,
and running it (from a given starting point for a given amount of time) yields a picture,
which can be sharpened to be a subset of the plane.
Since everything in reaction-diffusion land is continuous,
if you plot the "diagonal" like this, you get a figure which
(like Mandelbrot) exhibits all the possible behaviors of different parameters.
A patch near a particular spot ``looks like'' that the output of the system with those parameters.
https://www.karlsims.com/rd-exhibit.html
https://www.karlsims.com/rd.html

W: (A -> A -> B) -> A -> B = \xy.xyy
is another combinator.
If we produced this invariant via S, then the A in the type would be V and the B in the type would be Z/2Z: (V->V->Z/2Z)->V->Z/2Z
Again, this is a little like diagonalizing. If we had a map from V to V->Z/2Z, then we could
take an object of V, and produce a map, and also feed itself into that map. 

I don't think highly of W because it doesn't have a ``free parameter''. 

APPENDIX

More theorems (purportedly from Meyer and Bunder "condensed detachment and combinators" report TR-ARP-8/88, 1988, but copied out of from Hindley BCK and BCI Logics, Condensed Detachment
and the 2-Property)

(a->a')->(b->b')->(a'->b)->(a->b)
= \uvwx.v(w(ux))
(a->a')->(b->c->c')->b->(c'->a)->(c->a')
= \uvwxy.u(x(vwy))
(a->a')->(b->c->c')->b->(a'->c)->(a->c')
= \uvwxy.vw(x(uy))
(a->c->c')->(b->c'->c'')->a->b->c->c''
= \uvwxy.vx(uwy)

More theorems (purportedly from Jaskowski, Uber Tautologien, in welchen keine Variable mehr zweimal vorkommt," Zeitschrift fur Mathematische Logik und Grundlagen der Mathematik, vol. 9 (1963), pp. 219-228, but again copied out of Hindley)

a1-> ... -> an -> (a1 -> ... -> an -> b) -> b
= \u1...un v. v u1 ... un
(a -> b1 -> ... -> bn -> a' -> c) -> (a' -> b1 -> ... -> bn -> a -> c)
= \uv w1 ... wn x .  u x w1 ... wn v
(a -> b -> c) -> (d -> a) -> (b -> d -> c)
= \uvwx. u(vx)w
(a->a')->(b1-> ... -> bn -> a' -> c) -> d) -> (b1 -> ... -> bn -> a' -> c) -> d
= 



Possible examples of ``shadows'':
https://arxiv.org/pdf/math/0212377.pdf
and similarly
https://arxiv.org/pdf/math/0211454.pdf
John Baez talks about this kind of thing here:
https://math.ucr.edu/home/baez/week202.html

